{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Alert Investigation (Windows Process Alerts)\n",
    "\n",
    "**Notebook Version:** 1.0<br>\n",
    "**Python Version:** Python 3.6 (including Python 3.6 - AzureML)<br>\n",
    "**Required Packages**: kqlmagic, msticpy, pandas, numpy, matplotlib, networkx, ipywidgets, ipython, scikit_learn<br>\n",
    "**Platforms Supported**:<br>\n",
    "- Azure Notebooks Free Compute\n",
    "- Azure Notebooks DSVM\n",
    "- OS Independent\n",
    "\n",
    "**Data Sources Required**:<br>\n",
    "- Log Analytics - SecurityAlert, SecurityEvent (EventIDs 4688 and 4624/25)\n",
    "- (Optional) - VirusTotal (with API key)\n",
    "\n",
    "## Description:\n",
    "This notebook is intended for triage and investigation of security alerts. It is specifically targeted at alerts triggered by suspicious process activity on Windows hosts. Some of the sections will work on other types of alerts but this is not guaranteed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "## Table of Contents\n",
    "- [Setup and Authenticate](#setup)\n",
    "\n",
    "- [Get Alerts List](#getalertslist)\n",
    "- [Choose an Alert to investigate](#enteralertid)\n",
    "  - [Extract Properties and entities from alert](#extractalertproperties)\n",
    "  - [Entity Graph](#entitygraph)\n",
    "- [Related Alerts](#related_alerts)\n",
    "- [Session Process Tree](#processtree)\n",
    "  - [Process Timeline](#processtimeline)\n",
    "- [Other Process on Host](#process_clustering)\n",
    "- [Check for IOCs in Commandline](#cmdlineiocs)\n",
    "  - [VirusTotal lookup](#virustotallookup)\n",
    "- [Alert command line - Occurrence on other hosts in subscription](#cmdlineonotherhosts)\n",
    "- [Host Logons](#host_logons)\n",
    "  - [Alert Account](#logonaccount)\n",
    "  - [Failed Logons](#failed_logons)\n",
    "- [Appendices](#appendices)\n",
    "  - [Saving data to Excel](#appendices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>[Contents](#toc)\n",
    "# Setup\n",
    "\n",
    "1. Make sure that you have installed packages specified in the setup (uncomment the lines to execute)\n",
    "2. There are some manual steps up to selecting the alert ID. After this most of the notebook can be executed sequentially\n",
    "3. Major sections should be executable independently (e.g. Alert Command line and Host Logons can be run skipping Session Process Tree)\n",
    "\n",
    "## Install Packages\n",
    "The first time this cell runs for a new Azure Notebooks project or local Python environment it will take several minutes to download and install the packages. In subsequent runs it should run quickly and confirm that package dependencies are already installed. Unless you want to upgrade the packages you can feel free to skip execution of the next cell.\n",
    "\n",
    "If you see any import failures (```ImportError```) in the notebook, please re-run this cell and answer 'y', then re-run the cell where the failure occurred. \n",
    "\n",
    "Note you may see some warnings about package incompatibility with certain packages. This does not affect the functionality of this notebook but you may need to upgrade the packages producing the warnings to a more recent version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "MIN_REQ_PYTHON = (3,6)\n",
    "if sys.version_info < MIN_REQ_PYTHON:\n",
    "    print('Check the Kernel->Change Kernel menu and ensure that Python 3.6')\n",
    "    print('or later is selected as the active kernel.')\n",
    "    sys.exit(\"Python %s.%s or later is required.\\n\" % MIN_REQ_PYTHON)\n",
    "    \n",
    "# Package Installs - try to avoid if they are already installed\n",
    "try:\n",
    "    import msticpy.sectools as sectools\n",
    "    import Kqlmagic\n",
    "    print('If you answer \"n\" this cell will exit with an error in order to avoid the pip install calls,')\n",
    "    print('This error can safely be ignored.')\n",
    "    resp = input('msticpy and Kqlmagic packages are already loaded. Do you want to re-install? (y/n)')\n",
    "    if resp.strip().lower() != 'y':\n",
    "        sys.exit('pip install aborted - you may skip this error and continue.')\n",
    "    else:\n",
    "        print('After installation has completed, restart the current kernel and run '\n",
    "              'the notebook again skipping this cell.')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "print('\\nPlease wait. Installing required packages. This may take a few minutes...')\n",
    "!pip install git+https://github.com/microsoft/msticpy --upgrade --user\n",
    "!pip install Kqlmagic --no-cache-dir --upgrade --user\n",
    "\n",
    "print('\\nTo ensure that the latest versions of the installed libraries '\n",
    "      'are used, please restart the current kernel and run '\n",
    "      'the notebook again skipping this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get WorkspaceId\n",
    "To find your Workspace Id go to [Log Analytics](https://ms.portal.azure.com/#blade/HubsExtension/Resources/resourceType/Microsoft.OperationalInsights%2Fworkspaces). Look at the workspace properties to find the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import warnings\n",
    "MIN_REQ_PYTHON = (3,6)\n",
    "if sys.version_info < MIN_REQ_PYTHON:\n",
    "    print('Check the Kernel->Change Kernel menu and ensure that Python 3.6')\n",
    "    print('or later is selected as the active kernel.')\n",
    "    sys.exit(\"Python %s.%s or later is required.\\n\" % MIN_REQ_PYTHON)\n",
    "\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "sns.set()\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    " \n",
    "import msticpy.sectools as sectools\n",
    "import msticpy.nbtools as mas\n",
    "import msticpy.nbtools.kql as qry\n",
    "import msticpy.nbtools.nbdisplay as nbdisp\n",
    "\n",
    "# Some of our dependencies (networkx) still use deprecated Matplotlib\n",
    "# APIs - we can't do anything about it so suppress them from view\n",
    "from matplotlib import MatplotlibDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", category=MatplotlibDeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from msticpy.nbtools.wsconfig import WorkspaceConfig\n",
    "ws_config_file = 'config.json'\n",
    "\n",
    "WORKSPACE_ID = None\n",
    "TENANT_ID = None\n",
    "try:\n",
    "    ws_config = WorkspaceConfig(ws_config_file)\n",
    "    display(Markdown(f'Read Workspace configuration from local config.json for workspace **{ws_config[\"workspace_name\"]}**'))\n",
    "    for cf_item in ['tenant_id', 'subscription_id', 'resource_group', 'workspace_id', 'workspace_name']:\n",
    "        display(Markdown(f'**{cf_item.upper()}**: {ws_config[cf_item]}'))\n",
    "                     \n",
    "    if ('cookiecutter' not in ws_config['workspace_id'] or\n",
    "            'cookiecutter' not in ws_config['tenant_id']):\n",
    "        WORKSPACE_ID = ws_config['workspace_id']\n",
    "        TENANT_ID = ws_config['tenant_id']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not WORKSPACE_ID or not TENANT_ID:\n",
    "    display(Markdown('**Workspace configuration not found.**\\n\\n'\n",
    "                     'Please go to your Log Analytics workspace, copy the workspace ID'\n",
    "                     ' and/or tenant Id and paste here.<br> '\n",
    "                     'Or read the workspace_id from the config.json in your Azure Notebooks project.'))\n",
    "    ws_config = None\n",
    "    ws_id = mas.GetEnvironmentKey(env_var='WORKSPACE_ID',\n",
    "                              prompt='Please enter your Log Analytics Workspace Id:', auto_display=True)\n",
    "    ten_id = mas.GetEnvironmentKey(env_var='TENANT_ID',\n",
    "                              prompt='Please enter your Log Analytics Tenant Id:', auto_display=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate to Log Analytics\n",
    "If you are using user/device authentication, run the following cell. \n",
    "- Click the 'Copy code to clipboard and authenticate' button.\n",
    "- This will pop up an Azure Active Directory authentication dialog (in a new tab or browser window). The device code will have been copied to the clipboard. \n",
    "- Select the text box and paste (Ctrl-V/Cmd-V) the copied value. \n",
    "- You should then be redirected to a user authentication page where you should authenticate with a user account that has permission to query your Log Analytics workspace.\n",
    "\n",
    "Use the following syntax if you are authenticating using an Azure Active Directory AppId and Secret:\n",
    "```\n",
    "%kql loganalytics://tenant(aad_tenant).workspace(WORKSPACE_ID).clientid(client_id).clientsecret(client_secret)\n",
    "```\n",
    "instead of\n",
    "```\n",
    "%kql loganalytics://code().workspace(WORKSPACE_ID)\n",
    "```\n",
    "\n",
    "Note: you may occasionally see a JavaScript error displayed at the end of the authentication - you can safely ignore this.<br>\n",
    "On successful authentication you should see a ```popup schema``` button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENANT_ID = '72f988bf-86f1-41af-91ab-2d7cd011db47'\n",
    "WORKSPACE_ID = '52b1ab41-869e-4138-9e40-2a4457f09bf0'\n",
    "if not WORKSPACE_ID or not TENANT_ID:\n",
    "    try:\n",
    "        WORKSPACE_ID = ws_id.value\n",
    "        TENANT_ID = ten_id.value\n",
    "    except NameError:\n",
    "        raise ValueError('No workspace or Tenant Id.')\n",
    "\n",
    "mas.kql.load_kql_magic()\n",
    "%kql loganalytics://code().tenant(TENANT_ID).workspace(WORKSPACE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='getalertslist'></a>[Contents](#toc)\n",
    "# Get Alerts List\n",
    "\n",
    "Specify a time range to search for alerts. One this is set run the following cell to retrieve any alerts in that time window.\n",
    "You can change the time range and re-run the queries until you find the alerts that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "alert_origin = datetime(2019, 2, 13)\n",
    "alert_q_times = mas.QueryTime(units='day', max_before=20, before=5, \n",
    "                              max_after=1, origin_time=alert_origin)\n",
    "alert_q_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alert_counts = qry.list_alerts_counts(provs=[alert_q_times])\n",
    "alert_list = qry.list_alerts(provs=[alert_q_times])\n",
    "print(len(alert_counts), ' distinct alert types')\n",
    "print(len(alert_list), ' distinct alerts')\n",
    "display(HTML('<h2>Alert Timeline</h2>'))\n",
    "nbdisp.display_timeline(data=alert_list, source_columns = ['AlertName', 'CompromisedEntity'], title='Alerts', height=200)\n",
    "display(HTML('<h2>Top alerts</h2>'))\n",
    "alert_counts.head(20) # remove '.head(20)'' to see the full list grouped by AlertName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='enteralertid'></a>[Contents](#toc)\n",
    "# Choose Alert to Investigate\n",
    "Either pick an alert from a list of retrieved alerts or paste the SystemAlertId into the text box in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select alert from list\n",
    "As you select an alert, the main properties will be shown below the list.\n",
    "\n",
    "Use the filter box to narrow down your search to any substring in the AlertName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_alert = None\n",
    "alert_select = mas.AlertSelector(alerts=alert_list, action=nbdisp.display_alert)\n",
    "alert_select.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or paste in an alert ID and fetch it\n",
    "**Skip this if you selected from the above list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allow alert to be selected\n",
    "# Allow subscription to be selected\n",
    "get_alert = mas.GetSingleAlert(action=nbdisp.display_alert)\n",
    "get_alert.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extractalertproperties'></a>[Contents](#toc)\n",
    "## Extract properties and entities from Alert\n",
    "This section extracts the alert information and entities into a SecurityAlert object allowing us to query the properties more reliably. \n",
    "\n",
    "In particular, we use the alert to automatically provide parameters for queries and UI elements.\n",
    "Subsequent queries will use properties like the host name and derived properties such as the OS family (Linux or Windows) to adapt the query. Query time selectors like the one above will also default to an origin time that matches the alert selected.\n",
    "\n",
    "The alert view below shows all of the main properties of the alert plus the extended property dictionary (if any) and JSON representations of the Entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract entities and properties into a SecurityAlert class\n",
    "if ((alert_select is None or alert_select.selected_alert is None) and \n",
    "        (get_alert is None or get_alert.selected_alert is None)):\n",
    "    raise ValueError(\"Please select an alert before executing remaining cells.\")\n",
    "\n",
    "if get_alert is not None and get_alert.selected_alert is not None:\n",
    "    security_alert = mas.SecurityAlert(get_alert.selected_alert)\n",
    "elif alert_select.selected_alert is not None:\n",
    "    security_alert = mas.SecurityAlert(alert_select.selected_alert)\n",
    "    \n",
    "mas.disp.display_alert(security_alert, show_entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='entitygraph'></a>[Contents](#toc)\n",
    "## Entity Graph\n",
    "Depending on the type of alert there may be one or more entities attached as properties. Entities are things like Host, Account, IpAddress, Process, etc. - essentially the 'nouns' of security investigation. Events and alerts are the things that link them in actions so can be thought of as the verbs. Entities are often related to other entities - for example a process will usually have a related file entity (the process image) and an Account entity (the context in which the process was running). Endpoint alerts typically always have a host entity (which could be a physical or virtual machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot using Networkx/Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw the graph using Networkx/Matplotlib\n",
    "%matplotlib inline\n",
    "alertentity_graph = mas.create_alert_graph(security_alert)\n",
    "nbdisp.draw_alert_entity_graph(alertentity_graph, width=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='related_alerts'></a>[Contents](#toc)\n",
    "# Related Alerts\n",
    "For a subset of entities in the alert we can search for any alerts that have that entity in common. Currently this query looks for alerts that share the same Host, Account or Process and lists them below. \n",
    "**Notes:**\n",
    "- Some alert types do not include all of these entity types.\n",
    "- The original alert will be included in the \"Related Alerts\" set if it occurs within the query time boundary set below.\n",
    "\n",
    "The query time boundaries default to a longer period than when searching for the alert. You can extend the time boundary searched before or after the alert time. If the widget doesn't support the time boundary that you want you can change the max_before and max_after parameters in the call to QueryTime below to extend the possible time boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "query_times = mas.QueryTime(units='day', origin_time=security_alert.TimeGenerated, \n",
    "                            max_before=28, max_after=1, before=5)\n",
    "query_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not security_alert.primary_host:\n",
    "    print('Related alerts is not yet supported for alerts that are not host-based')\n",
    "    related_alerts = None\n",
    "else:\n",
    "    related_alerts = qry.list_related_alerts(provs=[query_times, security_alert])\n",
    "\n",
    "\n",
    "    if related_alerts is not None and not related_alerts.empty:\n",
    "        host_alert_items = related_alerts\\\n",
    "            .query('host_match == @True')[['AlertType', 'StartTimeUtc']]\\\n",
    "            .groupby('AlertType').StartTimeUtc.agg('count').to_dict()\n",
    "        acct_alert_items = related_alerts\\\n",
    "            .query('acct_match == @True')[['AlertType', 'StartTimeUtc']]\\\n",
    "            .groupby('AlertType').StartTimeUtc.agg('count').to_dict()\n",
    "        proc_alert_items = related_alerts\\\n",
    "            .query('proc_match == @True')[['AlertType', 'StartTimeUtc']]\\\n",
    "            .groupby('AlertType').StartTimeUtc.agg('count').to_dict()\n",
    "\n",
    "        def print_related_alerts(alertDict, entityType, entityName):\n",
    "            if len(alertDict) > 0:\n",
    "                print('Found {} different alert types related to this {} (\\'{}\\')'\n",
    "                      .format(len(alertDict), entityType, entityName))\n",
    "                for (k,v) in alertDict.items():\n",
    "                    print('    {}, Count of alerts: {}'.format(k, v))\n",
    "            else:\n",
    "                print('No alerts for {} entity \\'{}\\''.format(entityType, entityName))\n",
    "\n",
    "        print_related_alerts(host_alert_items, 'host', security_alert.hostname)\n",
    "        print_related_alerts(acct_alert_items, 'account', \n",
    "                             security_alert.primary_account.qualified_name \n",
    "                             if security_alert.primary_account\n",
    "                             else None)\n",
    "        print_related_alerts(proc_alert_items, 'process', \n",
    "                             security_alert.primary_process.ProcessFilePath \n",
    "                             if security_alert.primary_process\n",
    "                             else None)\n",
    "        nbdisp.display_timeline(data=related_alerts, source_columns = ['AlertName'], title='Alerts', height=100)\n",
    "    else:\n",
    "        display(Markdown('No related alerts found.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show these related alerts on a graph\n",
    "This should indicate which entities the other alerts are related to.\n",
    "\n",
    "This can be unreadable with a lot of alerts. Use the matplotlib interactive zoom control to zoom in to part of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw a graph of this (add to entity graph)\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "if related_alerts is not None and not related_alerts.empty:\n",
    "    rel_alert_graph = mas.add_related_alerts(related_alerts=related_alerts,\n",
    "                                             alertgraph=alertentity_graph)\n",
    "    nbdisp.draw_alert_entity_graph(rel_alert_graph, width=15)\n",
    "else:\n",
    "    display(Markdown('No related alerts found.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browse List of Related Alerts\n",
    "Select an Alert to view details. \n",
    "\n",
    "If you want to investigate that alert - copy its *SystemAlertId* property and open a new instance of this notebook to investigate this alert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def disp_full_alert(alert):\n",
    "    global related_alert\n",
    "    related_alert = mas.SecurityAlert(alert)\n",
    "    nbdisp.display_alert(related_alert, show_entities=True)\n",
    "\n",
    "if related_alerts is not None and not related_alerts.empty:\n",
    "    related_alerts['CompromisedEntity'] = related_alerts['Computer']\n",
    "    print('Selected alert is available as \\'related_alert\\' variable.')\n",
    "    rel_alert_select = mas.AlertSelector(alerts=related_alerts, action=disp_full_alert)\n",
    "    rel_alert_select.display()\n",
    "else:\n",
    "    display(Markdown('No related alerts found.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='processtree'></a>[Contents](#toc)\n",
    "# Get Process Tree\n",
    "If the alert has a process entity this section tries to retrieve the entire process tree to which that process belongs.\n",
    "\n",
    "Notes:\n",
    "- The alert must have a process entity\n",
    "- Only processes started within the query time boundary will be included\n",
    "- Ancestor and descented processes are retrieved to two levels (i.e. the parent and grandparent of the alert process plus any child and grandchild processes).\n",
    "- Sibling processes are the processes that share the same parent as the alert process\n",
    "- This can be a long-running query, especially if a wide time window is used! Caveat Emptor!\n",
    "\n",
    "The source (alert) process is shown in red.\n",
    "\n",
    "What's shown for each process:\n",
    "- Each process line is indented according to its position in the tree hierarchy\n",
    "- Top line fields:\n",
    "  - \\[relationship to source process:lev# - where # is the hops away from the source process\\]\n",
    "  - Process creation date-time (UTC)\n",
    "  - Process Image path\n",
    "  - PID - Process Id\n",
    "  - SubjSess - the session Id of the process spawning the new process\n",
    "  - TargSess - the new session Id if the process is launched in another context/session. If 0/0x0 then the process is launched in the same session as its parent\n",
    "- Second line fields:\n",
    "  - Process command line\n",
    "  - Account - name of the account context in which the process is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "query_times = mas.QueryTime(units='minute', origin_time=security_alert.origin_time)\n",
    "query_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from msticpy.nbtools.query_defns import DataFamily\n",
    "\n",
    "if security_alert.data_family != DataFamily.WindowsSecurity:\n",
    "    raise ValueError('The remainder of this notebook currently only supports Windows. '\n",
    "                     'Linux support is in development but not yet implemented.')\n",
    "\n",
    "def extract_missing_pid(security_alert):\n",
    "    for pid_ext_name in ['Process Id', 'Suspicious Process Id']:\n",
    "        pid = security_alert.ExtendedProperties.get(pid_ext_name, None)\n",
    "        if pid:\n",
    "            return pid\n",
    "\n",
    "def extract_missing_sess_id(security_alert):\n",
    "    sess_id = security_alert.ExtendedProperties.get('Account Session Id', None)\n",
    "    if sess_id:\n",
    "        return sess_id\n",
    "    for session in [e for e in security_alert.entities if\n",
    "                    e['Type'] == 'host-logon-session' or e['Type'] == 'hostlogonsession']:\n",
    "        return session['SessionId']\n",
    "            \n",
    "if (security_alert.primary_process):\n",
    "    # Do some patching up if the process entity doesn't have a PID\n",
    "    pid = security_alert.primary_process.ProcessId\n",
    "    if not pid:\n",
    "        pid = extract_missing_pid(security_alert)\n",
    "        if pid:\n",
    "            security_alert.primary_process.ProcessId = pid\n",
    "        else:\n",
    "            raise ValueError('Could not find the process Id for the alert process.')\n",
    "    \n",
    "    # Do the same if we can't find the account logon ID\n",
    "    if not security_alert.get_logon_id():\n",
    "        sess_id = extract_missing_sess_id(security_alert)\n",
    "        if sess_id and security_alert.primary_account:\n",
    "            security_alert.primary_account.LogonId = sess_id\n",
    "        else:\n",
    "            raise ValueError('Could not find the session Id for the alert process.')\n",
    "    \n",
    "    # run the query\n",
    "    process_tree = qry.get_process_tree(provs=[query_times, security_alert])\n",
    "\n",
    "    if len(process_tree) > 0:\n",
    "        # Print out the text view of the process tree\n",
    "        nbdisp.display_process_tree(process_tree)\n",
    "    else:\n",
    "        display(Markdown('No processes were returned so cannot obtain a process tree.'\n",
    "                     '\\n\\nSkip to [Other Processes](#process_clustering) later in the'\n",
    "                     ' notebook to retrieve all processes'))\n",
    "else:\n",
    "    display(Markdown('This alert has no process entity so cannot obtain a process tree.'\n",
    "                     '\\n\\nSkip to [Other Processes](#process_clustering) later in the'\n",
    "                     ' notebook to retrieve all processes'))\n",
    "    process_tree = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='processtimeline'></a>[Contents](#toc)\n",
    "## Process TimeLine\n",
    "This shows each process in the process tree on a timeline view.\n",
    "\n",
    "Labelling of individual process is very performance intensive and often results in nothing being displayed at all! Besides, for large numbers of processes it would likely result in an unreadable mess. \n",
    "\n",
    "Your main tools for negotiating the timeline are the Hover tool (toggled on and off by the speech bubble icon) and the wheel-zoom and pan tools (the former is an icon with an elipse and a magnifying glass, the latter is the crossed-arrows icon). The wheel zoom is particularly useful.\n",
    "\n",
    "As you hover over each process it will display the image name, PID and commandline.\n",
    "\n",
    "Also shown on the graphic is the timestamp line of the source/alert process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show timeline of events\n",
    "if process_tree is not None and not process_tree.empty:\n",
    "    nbdisp.display_timeline(data=process_tree, alert=security_alert, \n",
    "                            title='Alert Process Session', height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='process_clustering'></a>[Contents](#toc)\n",
    "# Other Processes on Host - Clustering\n",
    "Sometimes you don't have a source process to work with. Other times it's just useful to see what else is going on on the host. This section retrieves all processes on the host within the time bounds\n",
    "set in the query times widget.\n",
    "\n",
    "You can display the raw output of this by looking at the *processes_on_host* dataframe. Just copy this into a new cell and hit Ctrl-Enter.\n",
    "\n",
    "Usually though, the results return a lot of very repetitive and unintersting system processes so we attempt to cluster these to make the view easier to negotiate. \n",
    "To do this we process the raw event list output to extract a few features that render strings (such as commandline)into numerical values. The default below uses the following features:\n",
    "- commandLineTokensFull - this is a count of common delimiters in the commandline \n",
    "  (given by this regex r'[\\s\\-\\\\/\\.,\"\\'|&:;%$()]'). The aim of this is to capture the commandline structure while ignoring variations on what is essentially the same pattern (e.g. temporary path GUIDs, target IP or host names, etc.)\n",
    "- pathScore - this sums the ordinal (character) value of each character in the path (so /bin/bash and /bin/bosh would have similar scores).\n",
    "- isSystemSession - 1 if this is a root/system session, 0 if anything else.\n",
    "\n",
    "Then we run a clustering algorithm (DBScan in this case) on the process list. The result groups similar (noisy) processes together and leaves unique process patterns as single-member clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustered Processes (i.e. processes that have a cluster size > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msticpy.sectools.eventcluster import dbcluster_events, add_process_features\n",
    "\n",
    "processes_on_host = None\n",
    "if security_alert.primary_host:\n",
    "    processes_on_host = qry.list_processes(provs=[query_times, security_alert])\n",
    "\n",
    "    if processes_on_host is not None and not processes_on_host.empty:\n",
    "        feature_procs = add_process_features(input_frame=processes_on_host,\n",
    "                                             path_separator=security_alert.path_separator)\n",
    "\n",
    "        # you might need to play around with the max_cluster_distance parameter.\n",
    "        # decreasing this gives more clusters.\n",
    "        (clus_events, dbcluster, x_data) = dbcluster_events(data=feature_procs,\n",
    "                                                            cluster_columns=['commandlineTokensFull', \n",
    "                                                                             'pathScore', \n",
    "                                                                             'isSystemSession'],\n",
    "                                                            max_cluster_distance=0.0001)\n",
    "        print('Number of input events:', len(feature_procs))\n",
    "        print('Number of clustered events:', len(clus_events))\n",
    "        clus_events[['ClusterSize', 'processName']][clus_events['ClusterSize'] > 1].plot.bar(x='processName', \n",
    "                                                                                             title='Process names with Cluster > 1', \n",
    "                                                                                             figsize=(12,3));\n",
    "if processes_on_host is None or processes_on_host.empty:\n",
    "    display(Markdown('Unable to obtain any processes for this host. This feature'\n",
    "                     ' is currently only supported for Windows hosts.'\n",
    "                     '\\n\\nIf this is a Windows host skip to [Host Logons](#host_logons)'\n",
    "                     ' later in the notebook to examine logon events.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability in Command Lines and Process Names\n",
    "The top chart shows the variability of command line content for a give process name. The wider the box, the more instances were found with different command line structure \n",
    "\n",
    "Note, the 'structure' in this case is measured by the number of tokens or delimiters in the command line and does not look at content differences. This is done so that commonly varying instances of the same command line are grouped together.<br>\n",
    "For example `updatepatch host1.mydom.com` and `updatepatch host2.mydom.com` will be grouped together.\n",
    "\n",
    "The second chart shows the variability in executable path. This does compare content so `c:\\windows\\system32\\net.exe` and `e:\\windows\\system32\\net.exe` are treated as distinct. You would normally not expect to see any variability in this chart unless you have multiple copies of the same name executable or an executable is trying masquerade as another well-known binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Looking at the variability of commandlines and process image paths\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "if processes_on_host is not None and not processes_on_host.empty:\n",
    "    proc_plot = sns.catplot(y=\"processName\", x=\"commandlineTokensFull\", \n",
    "                            data=feature_procs.sort_values('processName'),\n",
    "                            kind='box', height=10)\n",
    "    proc_plot.fig.suptitle('Variability of Commandline Tokens', x=1, y=1)\n",
    "\n",
    "    proc_plot = sns.catplot(y=\"processName\", x=\"pathLogScore\", \n",
    "                            data=feature_procs.sort_values('processName'),\n",
    "                            kind='box', height=10, hue='isSystemSession')\n",
    "    proc_plot.fig.suptitle('Variability of Path', x=1, y=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top graph shows that, for a given process, some have a wide variability in their command line content while the majority have little or none. Looking at a couple of examples - like cmd.exe, powershell.exe, reg.exe, net.exe - we can recognize several common command line tools.\n",
    "\n",
    "The second graph shows processes by full process path content. We wouldn't normally expect to see variation here - as is the cast with most. There is also quite a lot of variance in the score making it a useful proxy feature for unique path name (this means that proc1.exe and proc2.exe that have the same commandline score won't get collapsed into the same cluster).\n",
    "\n",
    "Any process with a spread of values here means that we are seeing the same process name (but not necessarily the same file) is being run from different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'clus_events' in locals() and not clus_events.empty:\n",
    "    resp = input('View the clustered data? y/n')\n",
    "    if resp == 'y':\n",
    "        display(clus_events.sort_values('TimeGenerated')[['TimeGenerated', 'LastEventTime',\n",
    "                                                          'NewProcessName', 'CommandLine', \n",
    "                                                          'ClusterSize', 'commandlineTokensFull',\n",
    "                                                          'pathScore', 'isSystemSession']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at clusters for individual process names\n",
    "def view_cluster(exe_name):\n",
    "    display(clus_events[['ClusterSize', 'processName', 'CommandLine', 'ClusterId']][clus_events['processName'] == exe_name])\n",
    "    \n",
    "display(Markdown('You can view the cluster members for individual processes'\n",
    "                 'by inserting a new cell and entering:<br>'\n",
    "                 '`>>> view_cluster(process_name)`<br></div>'\n",
    "                 'where process_name is the unqualified process binary. E.g<br>'\n",
    "                 '`>>> view_cluster(\\'reg.exe\\')`'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time showing clustered vs. original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show timeline of events - clustered events\n",
    "if 'clus_events' in locals() and not clus_events.empty:\n",
    "    nbdisp.display_timeline(data=clus_events, \n",
    "                            overlay_data=processes_on_host, \n",
    "                            alert=security_alert, \n",
    "                            title='Distinct Host Processes (top) and All Proceses (bottom)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cmdlineiocs'></a>[Contents](#toc)\n",
    "# Base64 Decode and Check for IOCs\n",
    "This section looks for Indicators of Compromise (IoC) within the data sets passed to it.\n",
    "\n",
    "The first section looks at the commandline for the alert process (if any). It also looks for base64 encoded strings within the data - this is a common way of hiding attacker intent. It attempts to decode any strings that look like base64. Additionally, if the base64 decode operation returns any items that look like a base64 encoded string or file, a gzipped binary sequence, a zipped or tar archive, it will attempt to extract the contents before searching for potentially interesting items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = security_alert.primary_process\n",
    "ioc_extractor = sectools.IoCExtract()\n",
    "\n",
    "if process:\n",
    "    # if nothing is decoded this just returns the input string unchanged\n",
    "    base64_dec_str, _ = sectools.b64.unpack_items(input_string=process[\"CommandLine\"])\n",
    "    if base64_dec_str and '<decoded' in base64_dec_str:\n",
    "        print('Base64 encoded items found.')\n",
    "        print(base64_dec_str)\n",
    "        \n",
    "    # any IoCs in the string?\n",
    "    iocs_found = ioc_extractor.extract(base64_dec_str)\n",
    "    \n",
    "    if iocs_found:\n",
    "        print('\\nPotential IoCs found in alert process:')\n",
    "        display(iocs_found)\n",
    "else:\n",
    "    print('Nothing to process')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we have a process tree, look for IoCs in the whole data set\n",
    "You can replace the data=process_tree parameter to ioc_extractor.extract() to pass other data frames.\n",
    "use the columns parameter to specify which column or columns that you want to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc_extractor = sectools.IoCExtract()\n",
    "\n",
    "source_processes = None\n",
    "# if process tree is populated we use that preferentially\n",
    "try:\n",
    "    if not process_tree.empty:\n",
    "        source_processes = process_tree\n",
    "except (NameError, AttributeError):\n",
    "    pass \n",
    "\n",
    "# If not, use the clustered events from the all sessions\n",
    "try:\n",
    "    if source_processes is None and not clus_events.empty:\n",
    "        source_processes = clus_events\n",
    "except (NameError, AttributeError):\n",
    "    pass\n",
    "    \n",
    "if source_processes is not None and not source_processes.empty: \n",
    "    ioc_df = ioc_extractor.extract(data=source_processes, \n",
    "                                   columns=['CommandLine'], \n",
    "                                   os_family=security_alert.os_family,\n",
    "                                   ioc_types=['ipv4', 'ipv6', 'dns', 'url',\n",
    "                                              'md5_hash', 'sha1_hash', 'sha256_hash'])\n",
    "    if len(ioc_df):\n",
    "        display(HTML(\"<h3>IoC patterns found in process tree.</h3>\"))\n",
    "        display(ioc_df)\n",
    "else:\n",
    "    ioc_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If any Base64 encoded strings, decode and search for IoCs in the results.\n",
    "For simple strings the Base64 decoded output is straightforward. However for nested encodings this can get a little complex and difficult to represent in a tabular format.\n",
    "\n",
    "**Columns**\n",
    " - reference - The index of the row item in dotted notation in depth.seq pairs (e.g. 1.2.2.3 would be the 3 item at depth 3 that is a child of the 2nd item found at depth 1). This may not always be an accurate notation - it is mainly use to allow you to associate an individual row with the reference value contained in the full_decoded_string column of the topmost item).\n",
    " - original_string - the original string before decoding.\n",
    " - file_name - filename, if any (only if this is an item in zip or tar file).\n",
    " - file_type - a guess at the file type (this is currently elementary and only includes a few file types).\n",
    " - input_bytes - the decoded bytes as a Python bytes string.\n",
    " - decoded_string - the decoded string if it can be decoded as a UTF-8 or UTF-16 string. Note: binary sequences may often successfully decode as UTF-16 strings but, in these cases, the decodings are meaningless.\n",
    " - encoding_type - encoding type (UTF-8 or UTF-16) if a decoding was possible, otherwise 'binary'.\n",
    " - file_hashes - collection of file hashes for any decoded item.\n",
    " - md5 - md5 hash as a separate column.\n",
    " - sha1 - sha1 hash as a separate column.\n",
    " - sha256 - sha256 hash as a separate column.\n",
    " - printable_bytes - printable version of input_bytes as a string of \\xNN values\n",
    " - src_index - the index of the row in the input dataframe from which the data came.\n",
    " - full_decoded_string - the full decoded string with any decoded replacements. This is only really useful for top-level items, since nested items will only show the 'full' string representing the child fragment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source_processes is not None:\n",
    "    dec_df = sectools.b64.unpack_items(data=source_processes, column='CommandLine')\n",
    "    \n",
    "if source_processes is not None and not dec_df.empty:\n",
    "    display(HTML(\"<h3>Decoded base 64 command lines</h3>\"))\n",
    "    display(HTML(\"Warning - some binary patterns may be decodable as unicode strings\"))\n",
    "    display(dec_df[['full_decoded_string', 'original_string', 'decoded_string', 'input_bytes', 'file_hashes']])\n",
    "\n",
    "    ioc_dec_df = ioc_extractor.extract(data=dec_df, columns=['full_decoded_string'])\n",
    "    if len(ioc_dec_df):\n",
    "        display(HTML(\"<h3>IoC patterns found in base 64 decoded data</h3>\"))\n",
    "        display(ioc_dec_df)\n",
    "        if ioc_df is not None:\n",
    "            ioc_df = ioc_df.append(ioc_dec_df ,ignore_index=True)\n",
    "        else:\n",
    "            ioc_df = ioc_dec_df\n",
    "else:\n",
    "    print(\"No base64 encodings found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='virustotallookup'></a>[Contents](#toc)\n",
    "## Virus Total Lookup\n",
    "This section uses the popular Virus Total service to check any recovered IoCs against VTs database.\n",
    "\n",
    "To use this you need an API key from virus total, which you can obtain here: https://www.virustotal.com/.\n",
    "\n",
    "Note that VT throttles requests for free API keys to 4/minute. If you are unable to process the entire data set, try splitting it and submitting smaller chunks.\n",
    "\n",
    "**Things to note:**\n",
    "- Virus Total lookups include file hashes, domains, IP addresses and URLs.\n",
    "- The returned data is slightly different depending on the input type\n",
    "- The VTLookup class tries to screen input data to prevent pointless lookups. E.g.:\n",
    "  - Only public IP Addresses will be submitted (no loopback, private address space, etc.)\n",
    "  - URLs with only local (unqualified) host parts will not be submitted.\n",
    "  - Domain names that are unqualified will not be submitted.\n",
    "  - Hash-like strings (e.g 'AAAAAAAAAAAAAAAAAA') that do not appear to have enough entropy to be a hash will not be submitted.\n",
    "\n",
    "**Output Columns**\n",
    " - Observable - The IoC observable submitted\n",
    " - IoCType - the IoC type\n",
    " - Status - the status of the submission request\n",
    " - ResponseCode - the VT response code\n",
    " - RawResponse - the entire raw json response\n",
    " - Resource - VT Resource\n",
    " - SourceIndex - The index of the Observable in the source DataFrame. You can use this to rejoin to your original data.\n",
    " - VerboseMsg - VT Verbose Message\n",
    " - ScanId - VT Scan ID if any\n",
    " - Permalink - VT Permanent URL describing the resource\n",
    " - Positives - If this is not zero, it indicates the number of malicious reports that VT holds for this observable.\n",
    " - MD5 - The MD5 hash, if any\n",
    " - SHA1 - The MD5 hash, if any\n",
    " - SHA256 - The MD5 hash, if any\n",
    " - ResolvedDomains - In the case of IP Addresses, this contains a list of all domains that resolve to this IP address\n",
    " - ResolvedIPs - In the case Domains, this contains a list of all IP addresses resolved from the domain.\n",
    " - DetectedUrls - Any malicious URLs associated with the observable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_key = mas.GetEnvironmentKey(env_var='VT_API_KEY',\n",
    "                           help_str='To obtain an API key sign up here https://www.virustotal.com/',\n",
    "                           prompt='Virus Total API key:')\n",
    "vt_key.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if vt_key.value and ioc_df is not None and not ioc_df.empty:\n",
    "    vt_lookup = sectools.VTLookup(vt_key.value, verbosity=2)\n",
    "\n",
    "    print(f'{len(ioc_df)} items in input frame')\n",
    "    supported_counts = {}\n",
    "    for ioc_type in vt_lookup.supported_ioc_types:\n",
    "        supported_counts[ioc_type] = len(ioc_df[ioc_df['IoCType'] == ioc_type])\n",
    "    print('Items in each category to be submitted to VirusTotal')\n",
    "    print('(Note: items have pre-filtering to remove obvious erroneous '\n",
    "          'data and false positives, such as private IPaddresses)')\n",
    "    print(supported_counts)\n",
    "    print('-' * 80)\n",
    "    vt_results = vt_lookup.lookup_iocs(data=ioc_df, type_col='IoCType', src_col='Observable')\n",
    "    \n",
    "    pos_vt_results = vt_results.query('Positives > 0')\n",
    "    if len(pos_vt_results) > 0:\n",
    "        display(HTML(f'<h3>{len(pos_vt_results)} Positive Results Found</h3>'))\n",
    "        display(pos_vt_results[['Observable', 'IoCType','Permalink', \n",
    "                                'ResolvedDomains', 'ResolvedIPs', \n",
    "                                'DetectedUrls', 'RawResponse']])\n",
    "    display(HTML('<h3>Other results</h3>'))\n",
    "    display(vt_results.query('Status == \"Success\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the raw response for a specific row.\n",
    "```\n",
    "import json\n",
    "row_idx = 0 # The row number from one of the above dataframes\n",
    "raw_response = json.loads(pos_vt_results['RawResponse'].loc[row_idx])\n",
    "raw_response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cmdlineonotherhosts'></a>[Contents](#toc)\n",
    "# Alert command line - Occurrence on other hosts in workspace\n",
    "To get a sense of whether the alert process is something that is occuring on other hosts, run this section.\n",
    "\n",
    "This might tell you that the alerted process is actually a commonly-run process and the alert is a false positive. Alternatively, it may tell you that a real infection or attack is happening on other hosts in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "query_times = mas.QueryTime(units='day', before=5, max_before=20,\n",
    "                            after=1, max_after=10,\n",
    "                            origin_time=security_alert.origin_time)\n",
    "query_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# API ILLUSTRATION - Find the query to use\n",
    "qry.list_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# API ILLUSTRATION - What does the query look like?\n",
    "qry.query_help('list_hosts_matching_commandline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query needs a commandline parameter which isn't supplied\n",
    "# by default from the the alert \n",
    "# - so extract and escape this from the process\n",
    "if not security_alert.primary_process:\n",
    "    raise ValueError('This alert has no process entity. This section is not applicable.')\n",
    "\n",
    "proc_match_in_ws = None\n",
    "commandline = security_alert.primary_process.CommandLine\n",
    "commandline = mas.utility.escape_windows_path(commandline)\n",
    "\n",
    "if commandline.strip():\n",
    "    proc_match_in_ws = qry.list_hosts_matching_commandline(provs=[query_times, security_alert],\n",
    "                                                          commandline=commandline)\n",
    "else:\n",
    "    print('process has empty commandline')\n",
    "# Check the results\n",
    "if proc_match_in_ws is None or proc_match_in_ws.empty:\n",
    "    print('No proceses with matching commandline found in on other hosts in workspace')\n",
    "    print('between', query_times.start, 'and', query_times.end)\n",
    "else:\n",
    "    hosts = proc_match_in_ws['Computer'].drop_duplicates().shape[0]\n",
    "    processes = proc_match_in_ws.shape[0]\n",
    "    print('{numprocesses} proceses with matching commandline found on {numhosts} hosts in workspace'\\\n",
    "         .format(numprocesses=processes, numhosts=hosts))\n",
    "    print('between', query_times.start, 'and', query_times.end)\n",
    "    print('To examine these execute the dataframe \\'{}\\' in a new cell'.format('proc_match_in_ws'))\n",
    "    print(proc_match_in_ws[['TimeCreatedUtc','Computer', 'NewProcessName', 'CommandLine']].head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='host_logons'></a>[Contents](#toc)\n",
    "# Host Logons\n",
    "This section retrieves the logon events on the host in the alert.\n",
    "\n",
    "You may want to use the query times to search over a broader range than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "query_times = mas.QueryTime(units='day', origin_time=security_alert.origin_time,\n",
    "                           before=1, after=0, max_before=20, max_after=1)\n",
    "query_times.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='logonaccount'></a>[Contents](#toc)\n",
    "## Alert Logon Account\n",
    "The logon associated with the process in the alert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logon_id = security_alert.get_logon_id()\n",
    "\n",
    "if logon_id:\n",
    "    if logon_id in ['0x3e7', '0X3E7', '-1', -1]:\n",
    "        print('Cannot retrieve single logon event for system logon id '\n",
    "              '- please continue with All Host Logons below.')\n",
    "    else:\n",
    "        logon_event = qry.get_host_logon(provs=[query_times, security_alert])\n",
    "        nbdisp.display_logon_data(logon_event, security_alert)\n",
    "else:\n",
    "    print('No account entity in the source alert or the primary account had no logonId value set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Host Logons\n",
    "Since the number of logon events may be large and, in the case of system logons, very repetitive, we use clustering to try to identity logons with unique characteristics.\n",
    "\n",
    "In this case we use the numeric score of the account name and the logon type (i.e. interactive, service, etc.). The results of the clustered logons are shown below along with a more detailed, readable printout of the logon event information. The data here will vary depending on whether this is a Windows or Linux host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from msticpy.sectools.eventcluster import dbcluster_events, add_process_features, _string_score\n",
    "\n",
    "if security_alert.primary_host:\n",
    "    host_logons = qry.list_host_logons(provs=[query_times, security_alert])\n",
    "else:\n",
    "    host_logons = None\n",
    "    print(\"No data available - alert has no host entity.\")\n",
    "    \n",
    "if host_logons is not None and not host_logons.empty:\n",
    "    logon_features = host_logons.copy()\n",
    "    logon_features['AccountNum'] = host_logons.apply(lambda x: _string_score(x.Account), axis=1)\n",
    "    logon_features['LogonHour'] = host_logons.apply(lambda x: x.TimeGenerated.hour, axis=1)\n",
    "\n",
    "    # you might need to play around with the max_cluster_distance parameter.\n",
    "    # decreasing this gives more clusters.\n",
    "    (clus_logons, _, _) = dbcluster_events(data=logon_features, time_column='TimeGenerated',\n",
    "                                           cluster_columns=['AccountNum',\n",
    "                                                            'LogonType'],\n",
    "                                                             max_cluster_distance=0.0001)\n",
    "    print('Number of input events:', len(host_logons))\n",
    "    print('Number of clustered events:', len(clus_logons))\n",
    "    print('\\nDistinct host logon patterns:')\n",
    "    display(clus_logons.sort_values('TimeGenerated'))\n",
    "else:\n",
    "    print('No logon events found for host.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display logon details\n",
    "if host_logons is not None:\n",
    "    nbdisp.display_logon_data(clus_logons, security_alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing All Logons with Clustered results relative to Alert time line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show timeline of events - all logons + clustered logons\n",
    "if host_logons is not None and not host_logons.empty:\n",
    "    nbdisp.display_timeline(data=host_logons, overlay_data=clus_logons,\n",
    "                             alert=security_alert, \n",
    "                             source_columns=['Account', 'LogonType'],\n",
    "                             title='All Host Logons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Process Session and Logon Events in Timelines\n",
    "This shows the timeline of the clustered logon events with the process tree obtained earlier. This allows you to get a sense of which logon was responsible for the process tree session whether any additional logons (e.g. creating a process as another user) might be associated with the alert timeline.\n",
    "\n",
    "*Note you should use the pan and zoom tools to align the timelines since the data may be over different time ranges.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show timeline of events - all events\n",
    "if host_logons is not None and not host_logons.empty:\n",
    "    nbdisp.display_timeline(data=clus_logons, source_columns=['Account', 'LogonType'],\n",
    "                             alert=security_alert,\n",
    "                             title='Clustered Host Logons', height=200)\n",
    "    try:\n",
    "        nbdisp.display_timeline(data=process_tree, alert=security_alert, title='Alert Process Session', height=200)\n",
    "    except (NameError, TypeError):\n",
    "        print('process_tree not available for this alert.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of Logon types by Account\n",
    "if host_logons is not None and not host_logons.empty:\n",
    "    display(host_logons[['Account', 'LogonType', 'TimeGenerated']]\n",
    "            .groupby(['Account','LogonType']).count()\n",
    "            .rename(columns={'TimeGenerated': 'LogonCount'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='failed logons'></a>[Contents](#toc)\n",
    "## Failed Logons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if security_alert.primary_host:\n",
    "    failedLogons = qry.list_host_logon_failures(provs=[query_times, security_alert])\n",
    "else:\n",
    "    print(\"No data available - alert has no host entity.\")\n",
    "    failedLogons = None\n",
    "    \n",
    "\n",
    "if failedLogons is not None and not failedLogons.empty:\n",
    "    display(print('No logon failures recorded for this host between {security_alert.start} and {security_alert.start}'))\n",
    "\n",
    "failedLogons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='appendices'></a>[Contents](#toc)\n",
    "# Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('List of current DataFrames in Notebook')\n",
    "print('-' * 50)\n",
    "current_vars = list(locals().keys())\n",
    "for var_name in current_vars:\n",
    "    if isinstance(locals()[var_name], pd.DataFrame) and not var_name.startswith('_'):\n",
    "        print(var_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to CSV\n",
    "To save the contents of a pandas DataFrame to an CSV\n",
    "use the following syntax\n",
    "```\n",
    "host_logons.to_csv('host_logons.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": [
     "todo"
    ]
   },
   "source": [
    "## Saving Data to Excel\n",
    "To save the contents of a pandas DataFrame to an Excel spreadsheet\n",
    "use the following syntax\n",
    "```\n",
    "writer = pd.ExcelWriter('myWorksheet.xlsx')\n",
    "my_data_frame.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "318.996px",
    "width": "320.994px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "406.193px",
    "left": "1468.4px",
    "right": "20px",
    "top": "120px",
    "width": "456.572px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
